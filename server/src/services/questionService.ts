import { Question, QuestionType, AnswerResult, QuestionResult, UserAnswer, Feedback } from '../types/question.js';
import { callGeminiAPI, parseLLMJSON } from './llmService.js';
import { getQuestionTemplate, getFeedbackTemplate } from './promptTemplates.js';
import { getFallbackQuestion } from './fallbackQuestions.js';

// æ¦‚å¿µæ±  - åŸºäºç”¨æˆ·æä¾›çš„11ä¸ªæ–¹å‘
const CONCEPT_POOL: Array<{ concept: string; types: QuestionType[]; description?: string }> = [
  // 1. LLMåŸºç¡€æ¦‚å¿µ
  { concept: 'LLM', types: ['match', 'mcq', 'discernment', 'short_answer'], description: 'ä»€ä¹ˆæ˜¯å¤§è¯­è¨€æ¨¡å‹ã€LLMçš„ç»“æ„ã€è®­ç»ƒæ–¹å¼ã€åº”ç”¨åœºæ™¯ã€å¦‚"next word prediction"ç­‰åŸç†' },
  { concept: 'LLM_structure', types: ['match', 'mcq'], description: 'LLMçš„ç»“æ„' },
  { concept: 'LLM_training', types: ['match', 'mcq'], description: 'LLMçš„è®­ç»ƒæ–¹å¼' },
  { concept: 'LLM_application', types: ['bucket', 'mcq'], description: 'LLMçš„åº”ç”¨åœºæ™¯' },
  
  // 2. æç¤ºè¯å·¥ç¨‹ï¼ˆPrompt Engineeringï¼‰
  { concept: 'prompt', types: ['match', 'discernment', 'mcq', 'short_answer'], description: 'å¦‚ä½•æ„å»ºæœ‰æ•ˆçš„æç¤ºè¯ã€å…¸å‹æç¤ºæ¨¡å¼ã€æç¤ºè¯å®ä¾‹ä¸æ¨¡æ¿' },
  { concept: 'prompt_engineering', types: ['match', 'mcq'], description: 'æç¤ºè¯å·¥ç¨‹' },
  { concept: 'prompt_patterns', types: ['match', 'mcq'], description: 'å…¸å‹æç¤ºæ¨¡å¼' },
  
  // 3. æ·±åº¦å­¦ä¹ åŸºç¡€
  { concept: 'deep_learning', types: ['match', 'mcq', 'discernment'], description: 'æ·±åº¦å­¦ä¹ æ˜¯ä»€ä¹ˆã€ç¥ç»ç½‘ç»œåŸºæœ¬ç»“æ„ã€æ¿€æ´»ã€å±‚ã€è®­ç»ƒè¿‡ç¨‹ç­‰å…¥é—¨çŸ¥è¯†' },
  { concept: 'neural_network', types: ['match', 'discernment', 'mcq'], description: 'ç¥ç»ç½‘ç»œåŸºæœ¬ç»“æ„' },
  { concept: 'activation', types: ['match', 'mcq'], description: 'æ¿€æ´»å‡½æ•°' },
  { concept: 'neural_layers', types: ['match', 'mcq'], description: 'ç¥ç»ç½‘ç»œå±‚' },
  
  // 4. æœºå™¨å­¦ä¹ åŸºç¡€
  { concept: 'machine_learning', types: ['match', 'mcq', 'discernment'], description: 'ç›‘ç£å­¦ä¹ ä¸æ— ç›‘ç£å­¦ä¹ åŒºåˆ«ã€æ ‡æ³¨æ•°æ®ä¸æ¨¡å‹å­¦ä¹ æµç¨‹ã€æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„å…³ç³»' },
  { concept: 'supervised_learning', types: ['match', 'mcq'], description: 'ç›‘ç£å­¦ä¹ ' },
  { concept: 'unsupervised_learning', types: ['match', 'mcq'], description: 'æ— ç›‘ç£å­¦ä¹ ' },
  { concept: 'labeled_data', types: ['match', 'mcq'], description: 'æ ‡æ³¨æ•°æ®' },
  
  // 5. AI/ML/æ·±åº¦å­¦ä¹ å…³ç³»æ¢³ç†
  { concept: 'AI_ML_DL_relation', types: ['match', 'mcq', 'bucket'], description: 'å¸®åŠ©åˆå­¦è€…ç†è§£AIã€æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€ç¥ç»ç½‘ç»œä¹‹é—´çš„åŒºåˆ«ä¸è”ç³»' },
  
  // 6. æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰
  { concept: 'RAG', types: ['match', 'mcq', 'discernment'], description: 'ä»€ä¹ˆæ˜¯RAGã€RAGçš„ç®€è¦åŸç†å’Œå·¥ä½œæµç¨‹ã€ä½¿ç”¨åœºæ™¯' },
  { concept: 'RAG_workflow', types: ['match', 'mcq'], description: 'RAGçš„å·¥ä½œæµç¨‹' },
  
  // 7. å‘é‡å’ŒåµŒå…¥ï¼ˆEmbeddingsï¼‰
  { concept: 'embedding', types: ['match', 'mcq', 'discernment'], description: 'ä»€ä¹ˆæ˜¯embeddingã€å‘é‡æ•°æ®åº“å’Œè¯­ä¹‰æ£€ç´¢çš„åŸºç¡€æ¦‚å¿µ' },
  { concept: 'vector_database', types: ['match', 'mcq'], description: 'å‘é‡æ•°æ®åº“' },
  { concept: 'semantic_search', types: ['match', 'mcq'], description: 'è¯­ä¹‰æ£€ç´¢' },
  
  // 8. Transformeræ¨¡å‹åŸç†
  { concept: 'transformer', types: ['match', 'mcq', 'discernment'], description: 'è‡ªæ³¨æ„åŠ›æœºåˆ¶ã€Transformeræ¶æ„åœ¨LLMä¸­çš„ä½œç”¨' },
  { concept: 'self_attention', types: ['match', 'mcq'], description: 'è‡ªæ³¨æ„åŠ›æœºåˆ¶' },
  
  // 9. ä¸Šä¸‹æ–‡çª—å£ä¸token
  { concept: 'context_window', types: ['match', 'mcq', 'discernment'], description: 'LLMçš„context windowã€tokenåŒ–åŸç†ã€å¦‚ä½•å½±å“è¾“å‡ºä¸ç†è§£' },
  { concept: 'token', types: ['match', 'mcq'], description: 'TokenåŒ–åŸç†' },
  { concept: 'tokenization', types: ['match', 'mcq'], description: 'TokenåŒ–' },
  
  // 10. å¾®è°ƒï¼ˆFine-Tuningï¼‰æ–¹æ³•
  { concept: 'finetuning', types: ['match', 'mcq', 'discernment'], description: 'ä»€ä¹ˆæ˜¯å¾®è°ƒã€ä¸ºä»€ä¹ˆéœ€è¦å¾®è°ƒå¤§æ¨¡å‹ã€åŸºç¡€æµç¨‹' },
  { concept: 'fine_tuning_reason', types: ['match', 'mcq'], description: 'ä¸ºä»€ä¹ˆéœ€è¦å¾®è°ƒå¤§æ¨¡å‹' },
  { concept: 'fine_tuning_process', types: ['match', 'mcq'], description: 'å¾®è°ƒçš„åŸºç¡€æµç¨‹' },
  
  // 11. è´£ä»»å’Œå®‰å…¨ä½¿ç”¨
  { concept: 'responsible_AI', types: ['bucket', 'mcq', 'discernment', 'short_answer'], description: 'ç”Ÿæˆå¼AIçš„åˆè§„ã€éšç§ã€å®‰å…¨ã€è¾“å‡ºè´¨é‡æ£€æŸ¥ä¸è¯„ä¼°ã€ä¼ä¸šå’Œæ•™å­¦åœºæ™¯ä¸‹çš„ä½¿ç”¨è§„èŒƒ' },
  { concept: 'AI_safety', types: ['bucket', 'mcq'], description: 'AIå®‰å…¨ä½¿ç”¨' },
  { concept: 'AI_quality_check', types: ['bucket', 'mcq'], description: 'è¾“å‡ºè´¨é‡æ£€æŸ¥ä¸è¯„ä¼°' },
];

// é¢˜å‹åˆ†é…ç­–ç•¥ï¼šå‰5é¢˜åŒ…å«æ‰€æœ‰4ç§åŸºç¡€é¢˜å‹ï¼Œç¬¬6é¢˜å›ºå®šä¸ºç®€ç­”é¢˜
const QUESTION_TYPES: QuestionType[] = ['match', 'bucket', 'mcq', 'discernment'];
const SHORT_ANSWER_TYPE: QuestionType = 'short_answer';

// æ¯ä¸ªsessionçš„é¢˜å‹é˜Ÿåˆ—ï¼ˆsessionId -> é¢˜å‹æ•°ç»„ï¼‰
const sessionTypeQueues = new Map<string, QuestionType[]>();
// æ¯ä¸ªsessionå·²ä½¿ç”¨çš„æ¦‚å¿µï¼ˆsessionId -> Set<concept>ï¼‰
const sessionUsedConcepts = new Map<string, Set<string>>();

/**
 * è·å–ä¸‹ä¸€ä¸ªåº”è¯¥ä½¿ç”¨çš„é¢˜å‹ï¼ˆç¡®ä¿å‡åŒ€åˆ†å¸ƒï¼‰
 */
function getNextQuestionType(sessionId: string, questionIndex: number, totalQuestions: number): QuestionType {
  // ç¬¬6é¢˜ï¼ˆç´¢å¼•5ï¼‰å›ºå®šä¸ºç®€ç­”é¢˜
  if (questionIndex === 5) {
    return SHORT_ANSWER_TYPE;
  }
  
  // è·å–æˆ–åˆå§‹åŒ–è¯¥sessionçš„é¢˜å‹é˜Ÿåˆ—
  if (!sessionTypeQueues.has(sessionId)) {
    // ç¡®ä¿å‰4é¢˜åŒ…å«æ‰€æœ‰åŸºç¡€é¢˜å‹
    const types = [...QUESTION_TYPES];
    // éšæœºæ‰“ä¹±
    for (let i = types.length - 1; i > 0; i--) {
      const j = Math.floor(Math.random() * (i + 1));
      [types[i], types[j]] = [types[j], types[i]];
    }
    const queue = [...types];
    // ç¬¬5é¢˜éšæœºé€‰æ‹©åŸºç¡€é¢˜å‹
    if (totalQuestions > 4) {
      queue.push(QUESTION_TYPES[Math.floor(Math.random() * QUESTION_TYPES.length)]);
    }
    sessionTypeQueues.set(sessionId, queue);
  }
  
  const queue = sessionTypeQueues.get(sessionId)!;
  return queue[questionIndex] || QUESTION_TYPES[Math.floor(Math.random() * QUESTION_TYPES.length)];
}

/**
 * ç”Ÿæˆé¢˜ç›®
 */
export async function generateQuestion(
  concept?: string,
  type?: QuestionType,
  questionIndex?: number,
  totalQuestions?: number,
  sessionId?: string,
  userInfo?: { age: number; role: 'student' | 'professional' | 'educator' | 'researcher' | 'entrepreneur' | 'other'; selfRating?: number }
): Promise<Question | null> {
  // å¦‚æœæŒ‡å®šäº†é¢˜å‹ï¼Œç›´æ¥ä½¿ç”¨
  let selectedType: QuestionType;
  if (type) {
    selectedType = type;
  } else if (questionIndex !== undefined && totalQuestions !== undefined && sessionId) {
    // ä½¿ç”¨é¢˜å‹åˆ†é…ç­–ç•¥
    selectedType = getNextQuestionType(sessionId, questionIndex, totalQuestions);
  } else {
    // éšæœºé€‰æ‹©
    selectedType = QUESTION_TYPES[Math.floor(Math.random() * QUESTION_TYPES.length)];
  }
  
  // è®°å½•é¢˜å‹ï¼Œç”¨äºé™çº§æ–¹æ¡ˆ
  const targetType = selectedType;
  
  // è·å–è¯¥sessionå·²ä½¿ç”¨çš„æ¦‚å¿µ
  const usedConcepts = sessionId 
    ? (sessionUsedConcepts.get(sessionId) || new Set<string>())
    : new Set<string>();
  
  // é€‰æ‹©æ¦‚å¿µï¼šä¼˜å…ˆé€‰æ‹©æ”¯æŒè¯¥é¢˜å‹çš„ã€æœªä½¿ç”¨çš„æ¦‚å¿µ
  let selected;
  if (concept) {
    selected = CONCEPT_POOL.find(c => c.concept === concept);
  } else {
    // ç­›é€‰æ”¯æŒè¯¥é¢˜å‹çš„æ¦‚å¿µ
    const availableConcepts = CONCEPT_POOL.filter(c => c.types.includes(selectedType));
    // ä¼˜å…ˆé€‰æ‹©æœªä½¿ç”¨çš„æ¦‚å¿µ
    const unusedConcepts = availableConcepts.filter(c => !usedConcepts.has(c.concept));
    const candidates = unusedConcepts.length > 0 ? unusedConcepts : availableConcepts;
    selected = candidates[Math.floor(Math.random() * candidates.length)];
  }
  
  if (!selected) {
    selected = CONCEPT_POOL[0];
  }
  
  // æ ‡è®°æ¦‚å¿µå·²ä½¿ç”¨ï¼ˆå¦‚æœæœ‰sessionIdï¼‰
  if (sessionId && (concept || questionIndex !== undefined)) {
    if (!sessionUsedConcepts.has(sessionId)) {
      sessionUsedConcepts.set(sessionId, new Set());
    }
    sessionUsedConcepts.get(sessionId)!.add(selected.concept);
  }
  
  const prompt = getQuestionTemplate(selectedType, selected.concept, selected.description, userInfo);
  
  const userLabel = userInfo ? `${userInfo.role}-L${userInfo.selfRating ?? 'N/A'}` : 'N/A';
  console.log(`ç”Ÿæˆé¢˜ç›® - Session: ${sessionId || 'N/A'}, ç´¢å¼•: ${questionIndex ?? 'N/A'}, é¢˜å‹: ${selectedType}, æ¦‚å¿µ: ${selected.concept}, ç”¨æˆ·: ${userLabel}`);
  
  try {
    const llmResponse = await callGeminiAPI({
      prompt,
      temperature: 0.8,
      maxTokens: 4096, // å¢åŠ tokené™åˆ¶ï¼Œé¿å…MAX_TOKENSé”™è¯¯
    });
    
    if (llmResponse.error || !llmResponse.content) {
      console.error('âŒ Failed to generate question - API error:', llmResponse.error);
      console.error('LLM response content:', llmResponse.content?.substring(0, 500));
      
      // å¦‚æœæ˜¯MAX_TOKENSé”™è¯¯ï¼Œå°è¯•å¢åŠ tokené™åˆ¶é‡è¯•
      if (llmResponse.error?.includes('MAX_TOKENS')) {
        console.warn('âš ï¸ MAX_TOKENS error, retrying with higher token limit...');
        try {
          const retryResponse = await callGeminiAPI({
            prompt,
            temperature: 0.8,
            maxTokens: 8192, // å¤§å¹…å¢åŠ tokené™åˆ¶
          });
          if (retryResponse.content) {
            console.log('âœ… Retry successful with higher token limit');
            const question = parseLLMJSON<Question>(retryResponse.content);
            if (question && validateQuestion(question)) {
              console.log('âœ… Question generated successfully after retry');
              return question;
            }
          }
        } catch (retryError: any) {
          console.error('âŒ Retry also failed:', retryError);
        }
      }
      
      // å¦‚æœæ˜¯é…é¢è¶…é™æˆ–å…¶ä»–ä¸¥é‡é”™è¯¯ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ
      if (llmResponse.error?.includes('429') || llmResponse.error?.includes('quota')) {
        console.warn('âš ï¸ API quota exceeded, using fallback question');
        const fallbackQuestion = getFallbackQuestion(targetType, questionIndex ?? 0);
        if (fallbackQuestion) {
          console.log('âœ… Using fallback question, type:', fallbackQuestion.type, 'concept:', fallbackQuestion.concept);
          // ç¡®ä¿æ¦‚å¿µæ ‡è®°æ­£ç¡®
          if (sessionId && questionIndex !== undefined) {
            if (!sessionUsedConcepts.has(sessionId)) {
              sessionUsedConcepts.set(sessionId, new Set());
            }
            sessionUsedConcepts.get(sessionId)!.add(fallbackQuestion.concept);
          }
          return fallbackQuestion;
        }
      }
      
      return null;
    }
    
    console.log('ğŸ“„ LLMè¿”å›å†…å®¹é¢„è§ˆ:', llmResponse.content.substring(0, 200));
    
    const question = parseLLMJSON<Question>(llmResponse.content);
    
    if (!question) {
      console.error('âŒ è§£æé¢˜ç›®JSONå¤±è´¥');
      console.error('åŸå§‹å†…å®¹å‰500å­—ç¬¦:', llmResponse.content.substring(0, 500));
      return null;
    }
    
    // æ ¡éªŒé¢˜ç›®æ ¼å¼
    if (!validateQuestion(question)) {
      console.error('âŒ é¢˜ç›®æ ¼å¼æ ¡éªŒå¤±è´¥');
      console.error('é¢˜ç›®å†…å®¹:', JSON.stringify(question, null, 2));
      return null;
    }
    
    console.log('âœ… é¢˜ç›®ç”ŸæˆæˆåŠŸ - ç±»å‹:', question.type, 'æ¦‚å¿µ:', question.concept);
    return question;
  } catch (error: any) {
    console.error('âŒ ç”Ÿæˆé¢˜ç›®æ—¶å‘ç”Ÿå¼‚å¸¸:', error);
    console.error('å¼‚å¸¸å †æ ˆ:', error.stack);
    return null;
  }
}

/**
 * æ¸…ç†sessionçš„é¢˜ç›®ç”Ÿæˆç›¸å…³æ•°æ®
 */
export function clearSessionQuestionData(sessionId: string): void {
  sessionTypeQueues.delete(sessionId);
  sessionUsedConcepts.delete(sessionId);
}

/**
 * æ ¡éªŒé¢˜ç›®æ ¼å¼
 */
function validateQuestion(question: Question): boolean {
  if (!question.type || !question.question_text || !question.short_explanation) {
    return false;
  }
  
  switch (question.type) {
    case 'match':
      const match = question as any;
      return !!(
        match.options_left?.length &&
        match.options_right?.length &&
        match.answer_key?.length &&
        match.options_left.length === match.answer_key.length
      );
    
    case 'bucket':
      const bucket = question as any;
      return !!(
        bucket.cards?.length &&
        bucket.buckets?.length &&
        bucket.answer_key &&
        Object.keys(bucket.answer_key).length === bucket.cards.length
      );
    
    case 'mcq':
      const mcq = question as any;
      return !!(
        mcq.options?.length &&
        mcq.correct_options?.length
      );
    
    case 'discernment':
      const disc = question as any;
      return !!(disc.statement && typeof disc.correct_answer === 'boolean');
    
    case 'short_answer':
      const shortAnswer = question as any;
      return !!(
        shortAnswer.scenario &&
        shortAnswer.key_points &&
        Array.isArray(shortAnswer.key_points) &&
        shortAnswer.key_points.length > 0
      );
    
    default:
      return false;
  }
}

/**
 * è¯„ä¼°ç­”æ¡ˆ
 */
export function evaluateAnswer(question: Question, userAnswer: UserAnswer): AnswerResult {
  switch (question.type) {
    case 'match': {
      const matchQ = question as any;
      const userMatches = userAnswer.answer.matches || [];
      const correctMatches = matchQ.answer_key;
      
      // æ£€æŸ¥åŒ¹é…æ•°é‡
      if (userMatches.length !== correctMatches.length) {
        return 'incorrect';
      }
      
      // æ£€æŸ¥æ¯ä¸ªåŒ¹é…æ˜¯å¦æ­£ç¡®
      const correctCount = userMatches.filter(([left, right]: [string, string]) => {
        return correctMatches.some(([cLeft, cRight]: [string, string]) => 
          cLeft === left && cRight === right
        );
      }).length;
      
      if (correctCount === correctMatches.length) return 'correct';
      if (correctCount > 0) return 'partial';
      return 'incorrect';
    }
    
    case 'bucket': {
      const bucketQ = question as any;
      const userAssignments = userAnswer.answer.assignments || {};
      const correctAssignments = bucketQ.answer_key;
      
      const total = Object.keys(correctAssignments).length;
      let correctCount = 0;
      
      for (const [cardId, bucketId] of Object.entries(correctAssignments)) {
        if (userAssignments[cardId] === bucketId) {
          correctCount++;
        }
      }
      
      if (correctCount === total) return 'correct';
      if (correctCount > 0) return 'partial';
      return 'incorrect';
    }
    
    case 'mcq': {
      const mcqQ = question as any;
      const userSelected = userAnswer.answer.selected || [];
      const correctOptions = mcqQ.correct_options;
      
      if (userSelected.length !== correctOptions.length) {
        return 'incorrect';
      }
      
      const allCorrect = userSelected.every((id: string) => 
        correctOptions.includes(id)
      ) && correctOptions.every((id: string) => 
        userSelected.includes(id)
      );
      
      return allCorrect ? 'correct' : 'incorrect';
    }
    
    case 'discernment': {
      const discQ = question as any;
      return userAnswer.answer.answer === discQ.correct_answer ? 'correct' : 'incorrect';
    }
    
    case 'short_answer': {
      // ç®€ç­”é¢˜ä½¿ç”¨LLMè¯„ä¼°ç­”æ¡ˆè´¨é‡
      const userAnswerText = userAnswer.answer.answer || '';
      if (!userAnswerText.trim()) {
        return 'incorrect';
      }
      // ç®€ç­”é¢˜çš„è¯„ä¼°éœ€è¦åˆ†æç­”æ¡ˆå†…å®¹ï¼Œè¿™é‡Œå…ˆè¿”å›'partial'
      // å®é™…è¯„ä¼°ä¼šåœ¨generateFeedbackä¸­é€šè¿‡LLMè¿›è¡Œæ›´è¯¦ç»†çš„åˆ¤æ–­
      // ä½†ä¸ºäº†ä¿æŒä¸€è‡´æ€§ï¼Œæˆ‘ä»¬å…ˆç”¨ä¸€ä¸ªç®€å•çš„å¯å‘å¼è¯„ä¼°
      const shortAnswerQ = question as any;
      const keyPoints = shortAnswerQ.key_points || [];
      const answerLower = userAnswerText.toLowerCase();
      
      // ç®€å•æ£€æŸ¥ï¼šå¦‚æœç­”æ¡ˆé•¿åº¦å¤ªçŸ­ï¼Œå¯èƒ½ä¸å®Œæ•´
      if (userAnswerText.length < 20) {
        return 'incorrect';
      }
      
      // æ£€æŸ¥æ˜¯å¦æåˆ°äº†å…³é”®è¦ç‚¹ï¼ˆç®€å•å…³é”®è¯åŒ¹é…ï¼‰
      const mentionedPoints = keyPoints.filter((point: string) => {
        const pointKeywords = point.toLowerCase().split(/[\sï¼Œ,ã€‚ã€]/).filter(k => k.length > 1);
        return pointKeywords.some(keyword => answerLower.includes(keyword));
      });
      
      if (mentionedPoints.length === keyPoints.length) {
        return 'correct';
      } else if (mentionedPoints.length > 0) {
        return 'partial';
      }
      
      return 'partial'; // é»˜è®¤è¿”å›partialï¼Œè®©LLMåœ¨åé¦ˆä¸­è¯¦ç»†è¯„ä¼°
    }
    
    default:
      return 'incorrect';
  }
}

/**
 * ç”Ÿæˆå³æ—¶åé¦ˆï¼ˆæ ¹æ®ç”¨æˆ·å…·ä½“ç­”æ¡ˆï¼‰
 */
export async function generateFeedback(
  question: Question,
  result: AnswerResult,
  userAnswer: any,
  correctAnswer: any
): Promise<Feedback> {
  // å¯¹äºç®€ç­”é¢˜ï¼Œéœ€è¦å…ˆé€šè¿‡LLMè¯„ä¼°ç­”æ¡ˆè´¨é‡ï¼Œç„¶åç”Ÿæˆåé¦ˆ
  let finalResult = result;
  let isCorrect = result === 'correct';
  
  if (question.type === 'short_answer') {
    const userAnswerText = userAnswer.answer || '';
    const shortAnswerQ = question as any;
    const keyPoints = shortAnswerQ.key_points || [];
    
    // ä½¿ç”¨LLMè¯„ä¼°ç®€ç­”é¢˜ç­”æ¡ˆè´¨é‡ - å¿…é¡»æˆåŠŸï¼Œä¸å…è®¸fallback
    const evaluationPrompt = `
You are an AI literacy education expert. Please evaluate the quality of the user's answer to a short answer question.

Question scenario: ${shortAnswerQ.scenario || shortAnswerQ.question_text}

Key points (that need to be covered):
${keyPoints.map((p: string, i: number) => `${i + 1}. ${p}`).join('\n')}

User's answer: "${userAnswerText}"

**CRITICAL**: You MUST carefully read and analyze the user's actual answer content. Do not make assumptions. Base your evaluation on what the user actually wrote.

Please evaluate the quality of the user's answer and output in JSON format:
{
  "result": "correct" | "partial" | "incorrect",
  "reason": "Brief explanation of the evaluation (1-2 sentences) based on the user's actual answer"
}

Evaluation criteria:
- correct: The answer fully covers all key points with accurate understanding
- partial: The answer covers some points but is incomplete or has understanding deviations
- incorrect: The answer basically does not cover the key points, or has serious understanding errors

Output only JSON, no other text.
`;
    
    let evalResponse = await callGeminiAPI({
      prompt: evaluationPrompt,
      temperature: 0.3,
      maxTokens: 1024, // å¢åŠ tokené™åˆ¶ä»¥æ”¯æŒæ€è€ƒè¿‡ç¨‹
    });
    
    // å¦‚æœé‡åˆ°MAX_TOKENSé”™è¯¯ï¼Œè‡ªåŠ¨é‡è¯•
    if (evalResponse.error?.includes('MAX_TOKENS')) {
      console.warn('âš ï¸ Short answer evaluation hit MAX_TOKENS, retrying with higher limit...');
      try {
        evalResponse = await callGeminiAPI({
          prompt: evaluationPrompt,
          temperature: 0.3,
          maxTokens: 2048, // å¤§å¹…å¢åŠ tokené™åˆ¶
        });
        if (evalResponse.content) {
          console.log('âœ… Short answer evaluation retry successful with higher token limit');
        }
      } catch (retryError: any) {
        console.error('âŒ Short answer evaluation retry also failed:', retryError);
      }
    }
    
    if (evalResponse.error || !evalResponse.content) {
      throw new Error(`Failed to evaluate short answer: ${evalResponse.error || 'LLM did not return content'}`);
    }
    
    const evalResult = parseLLMJSON<{ result: AnswerResult; reason?: string }>(evalResponse.content);
    if (!evalResult || !evalResult.result) {
      throw new Error('Failed to parse short answer evaluation result');
    }
    
    finalResult = evalResult.result;
    isCorrect = finalResult === 'correct';
    console.log(`ğŸ“ Short answer evaluation result: ${finalResult}${evalResult.reason ? ` - ${evalResult.reason}` : ''}`);
  }
  
  const prompt = getFeedbackTemplate(
    question.type,
    question.concept,
    finalResult,
    question.short_explanation,
    question,
    userAnswer,
    correctAnswer
  );
  
  let llmResponse = await callGeminiAPI({
    prompt,
    temperature: 0.7,
    maxTokens: 2048, // å¢åŠ tokenä»¥æ”¯æŒæ›´è¯¦ç»†çš„åé¦ˆ
  });
  
  // å¦‚æœé‡åˆ°MAX_TOKENSé”™è¯¯ï¼Œè‡ªåŠ¨é‡è¯•
  if (llmResponse.error?.includes('MAX_TOKENS')) {
    console.warn('âš ï¸ Feedback generation hit MAX_TOKENS, retrying with higher limit...');
    try {
      llmResponse = await callGeminiAPI({
        prompt,
        temperature: 0.7,
        maxTokens: 4096, // å¤§å¹…å¢åŠ tokené™åˆ¶
      });
      if (llmResponse.content) {
        console.log('âœ… Feedback retry successful with higher token limit');
      }
    } catch (retryError: any) {
      console.error('âŒ Feedback retry also failed:', retryError);
    }
  }
  
  if (llmResponse.error || !llmResponse.content) {
    // NO FALLBACK - throw error if LLM fails
    console.error('âŒ LLM feedback generation failed:', llmResponse.error);
    throw new Error(`Failed to generate feedback: ${llmResponse.error || 'LLM did not return content'}`);
  }
  
  // å¯¹äºç®€ç­”é¢˜ï¼ŒisCorrectå§‹ç»ˆè®¾ä¸ºtrueï¼Œå› ä¸ºç®€ç­”é¢˜æ˜¯è¯„æè€Œä¸æ˜¯åˆ¤æ–­å¯¹é”™
  const finalIsCorrect = question.type === 'short_answer' ? true : isCorrect;
  
  return {
    message: llmResponse.content.trim(),
    isCorrect: finalIsCorrect,
  };
}

